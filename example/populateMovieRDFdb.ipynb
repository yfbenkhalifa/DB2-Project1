{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate an RDF database\n",
    "\n",
    "This notebook reports the main steps to download CSV files, process them and create an RDF dataset from them accordingly to an ontology. \n",
    "\n",
    "To measure execution time in Jupyter notebooks: <code>pip install ipython-autotime</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and URLs\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "moviesUrl = path + '/data/imdb/IMDb_movies.csv'\n",
    "namesUrl = path + '/data/imdb/IMDb_names.csv'\n",
    "joinTableUrl = path + '/data/imdb/IMDb_title_principals.csv'\n",
    "oscarsUrl = path + '/data/imdb/the_oscar_award.csv'\n",
    "\n",
    "# country codes\n",
    "countriesURL = path + '/data/countryCodes/wikipedia-iso-country-codes.csv'\n",
    "\n",
    "# saving folder\n",
    "savePath =  path + '/data/rdf/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                     object\n",
       "original_title            object\n",
       "year                       int32\n",
       "date_published            object\n",
       "genre                     object\n",
       "duration                   int64\n",
       "country                   object\n",
       "language                  object\n",
       "director                  object\n",
       "writer                    object\n",
       "production_company        object\n",
       "actors                    object\n",
       "description               object\n",
       "avg_vote                 float64\n",
       "votes                      int64\n",
       "budget                    object\n",
       "usa_gross_income          object\n",
       "worlwide_gross_income     object\n",
       "metascore                float64\n",
       "reviews_from_users       float64\n",
       "reviews_from_critics     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV files in memory\n",
    "movies = pd.read_csv(moviesUrl, sep=',', index_col='imdb_title_id')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the country codes\n",
    "# we need to convert NaN values to something else otherwise NA strings are converted to NaN -> problem with Namibia\n",
    "countries = pd.read_csv(countriesURL, sep=',', index_col='Name', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 85855 entries, tt0000009 to tt9914942\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   title                  85855 non-null  object \n",
      " 1   original_title         85855 non-null  object \n",
      " 2   year                   85855 non-null  int64  \n",
      " 3   date_published         85855 non-null  object \n",
      " 4   genre                  85855 non-null  object \n",
      " 5   duration               85855 non-null  int64  \n",
      " 6   country                85791 non-null  object \n",
      " 7   language               85022 non-null  object \n",
      " 8   director               85768 non-null  object \n",
      " 9   writer                 84283 non-null  object \n",
      " 10  production_company     81400 non-null  object \n",
      " 11  actors                 85786 non-null  object \n",
      " 12  description            83740 non-null  object \n",
      " 13  avg_vote               85855 non-null  float64\n",
      " 14  votes                  85855 non-null  int64  \n",
      " 15  budget                 23710 non-null  object \n",
      " 16  usa_gross_income       15326 non-null  object \n",
      " 17  worlwide_gross_income  31016 non-null  object \n",
      " 18  metascore              13305 non-null  float64\n",
      " 19  reviews_from_users     78258 non-null  float64\n",
      " 20  reviews_from_critics   74058 non-null  float64\n",
      "dtypes: float64(4), int64(3), object(14)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to install <code>RDFLib</code>\n",
    "\n",
    "<code>pip3 install rdflib </code> [Documentation](https://rdflib.readthedocs.io/en/stable/gettingstarted.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the country and the movie ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "MO = Namespace(\"http://www.dei.unipd.it/database2/movieOntology#\")\n",
    "\n",
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"mo\", MO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATE \n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 1.47 s, total: 1min 27s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in movies.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    Movie = URIRef(MO[index])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Movie, RDF.type, MO.Movie))\n",
    "    g.add((Movie, MO['originalTitle'], Literal(row['original_title'], datatype=XSD.string)))\n",
    "    g.add((Movie, MO['alternativeTitle'], Literal(row['title'], datatype=XSD.string)))\n",
    "    g.add((Movie, MO['releaseYear'], Literal(row['year'], datatype=XSD.gYear)))\n",
    "   \n",
    "    try:\n",
    "        datetime.datetime.strptime(str(row['date_published']), '%Y-%m-%d')\n",
    "        g.add((Movie, MO['releaseDate'], Literal(row['date_published'], datatype=XSD.date)))\n",
    "    except ValueError:\n",
    "        # probably it's the year alone\n",
    "        # check length\n",
    "        if (len(row['date_published'])==4):\n",
    "            #it is a year\n",
    "            g.add((Movie, MO['releaseDate'], Literal(row['date_published']+\"-01-01\", datatype=XSD.date)))\n",
    "\n",
    "    g.add((Movie, MO['duration'], Literal(row['duration'], datatype=XSD.integer)))\n",
    "\n",
    "    ## how to handle genre\n",
    "    #there can be more than one genre per movie\n",
    "    for gN in row['genre'].split(','):\n",
    "        Genre = URIRef(MO[gN.strip()])\n",
    "        g.add((Movie, MO['hasGenre'], Genre))    \n",
    "\n",
    "    ## handle country\n",
    "    #there can be more than one country per movie\n",
    "    for c in str(row['country']).split(','):\n",
    "        cName = c.strip()\n",
    "        # check if the country exists\n",
    "        # country.index == x returns an array of booleans, thus we need to use the any() method\n",
    "        if((countries.index == cName).any() == True):\n",
    "            #get the country code, convert to string and get the lower case to match the country codes in the ontology \n",
    "            code = str(countries[countries.index == cName]['Alpha-2 code'][0]).lower()\n",
    "            # create the RDF node\n",
    "            Country = URIRef(CNS[code])\n",
    "            # add the edge connecting the Movie and the Country \n",
    "            g.add((Movie, MO['hasCountry'], Country))    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: user 1min 3s, sys: 1.04 s, total: 1min 4s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'movies.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referential integrity\n",
    "Note that in RDF we are in an open world situation. We cannot guarantee the referential integrity between the entities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person\n",
    "\n",
    "Let us generate the RDF data relative to the movie workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "people = pd.read_csv(namesUrl, sep=',', index_col='imdb_name_id', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 297705 entries, nm0000001 to nm3834123\n",
      "Data columns (total 16 columns):\n",
      "name                     297705 non-null object\n",
      "birth_name               297705 non-null object\n",
      "height                   297705 non-null object\n",
      "bio                      297705 non-null object\n",
      "birth_details            297705 non-null object\n",
      "date_of_birth            297705 non-null object\n",
      "place_of_birth           297705 non-null object\n",
      "death_details            297705 non-null object\n",
      "date_of_death            297705 non-null object\n",
      "place_of_death           297705 non-null object\n",
      "reason_of_death          297705 non-null object\n",
      "spouses_string           297705 non-null object\n",
      "spouses                  297705 non-null int64\n",
      "divorces                 297705 non-null int64\n",
      "spouses_with_children    297705 non-null int64\n",
      "children                 297705 non-null int64\n",
      "dtypes: int64(4), object(12)\n",
      "memory usage: 38.6+ MB\n"
     ]
    }
   ],
   "source": [
    "people.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People are modeled with the FOAF ontology. \n",
    "Refer to [FOAF Documentation](http://xmlns.com/foaf/spec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new graph\n",
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 1.43 s, total: 1min 27s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the person dataframe\n",
    "for index, row in people.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the person id as URI\n",
    "    Person = URIRef(MO[index])\n",
    "    g.add((Person, RDF.type, FOAF.Person))\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Person, FOAF['name'], Literal(row['name'], datatype=XSD.string)))\n",
    "    if row['date_of_birth'] != '':\n",
    "        try:\n",
    "            datetime.datetime.strptime(str(row['date_of_birth']), '%Y-%m-%d')\n",
    "            g.add((Person, MO['birthday'], Literal(row['date_of_birth'], datatype=XSD.date)))\n",
    "        except ValueError:\n",
    "            # probably it's the year alone\n",
    "            # check length\n",
    "            if (len(row['date_of_birth'])==4):\n",
    "                #it is a year\n",
    "                g.add((Person, MO['birthday'], Literal(row['date_of_birth']+\"-01-01\", datatype=XSD.date)))\n",
    "    \n",
    "    if row['place_of_birth'] != '':\n",
    "        g.add((Person, MO['birthplace'], Literal(row['place_of_birth'], datatype=XSD.string)))\n",
    "    \n",
    "    # check if the death day is not empty--i.e., the person is still alive\n",
    "    if row['date_of_death'] != '':\n",
    "        try:\n",
    "            datetime.datetime.strptime(str(row['date_of_death']), '%Y-%m-%d')\n",
    "            g.add((Person, MO['deathDay'], Literal(row['date_of_death'], datatype=XSD.date)))\n",
    "        except ValueError:\n",
    "            # probably it's the year alone\n",
    "            # check length\n",
    "            if (len(row['date_of_death'])==4):\n",
    "                #it is a year\n",
    "                g.add((Person, MO['deathDay'], Literal(row['date_of_death']+\"-01-01\", datatype=XSD.date)))\n",
    "        \n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"mo\", MO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: user 1min 19s, sys: 1.31 s, total: 1min 20s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'names.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person-Movie Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "join = pd.read_csv(joinTableUrl, sep=',', index_col='imdb_title_id', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new graph\n",
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular expressions\n",
    "import re\n",
    "actor = re.compile('act*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 2.18 s, total: 2min 24s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the join table dataframe\n",
    "for index, row in join.iterrows():\n",
    "    # Create the node about the movie\n",
    "    # note that we do not add this resource to the database (created before)\n",
    "    Movie = URIRef(MO[index])\n",
    "    \n",
    "    # Create the node about the person\n",
    "    # note that we do not add this resource to the database (created before)\n",
    "    Person = URIRef(MO[row['imdb_name_id']])\n",
    "    # get the role of the person\n",
    "    role = row['category']\n",
    "    \n",
    "    # we have an actor or actress\n",
    "    if actor.match(role): \n",
    "        g.add((Person, MO['acted'], Movie))\n",
    "    elif (role=='director'):\n",
    "        g.add((Person, MO['directed'], Movie))\n",
    "    else:\n",
    "        # note that, with the defined ontology, we cannot caracterize the specific role of this person in the movie. \n",
    "        # why?\n",
    "        g.add((Person, MO['worked'], Movie))\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"mo\", MO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: user 1min 20s, sys: 1.57 s, total: 1min 22s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'name_movie_join.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awards - Oscars data\n",
    "Note that if we do not check the referential integrity then we could produce ghost triple movie-nominee-oscar where the movie is not in the RDF graph.\n",
    "\n",
    "On the other hand, we can check if an actor or a movie exists by using the DataFrame in Python. Note that this is an external check and not a constraints met by the RDF DB.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "oscars = pd.read_csv(oscarsUrl, sep=',', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "import string\n",
    "import re\n",
    "#create a new graph\n",
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 53s, sys: 4.85 s, total: 4min 58s\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#iterate over the join table dataframe\n",
    "for index,row in oscars.iterrows():\n",
    "    #create the oscar with a custom id \n",
    "    cat = re.sub(r'[^\\w\\s]','',row['category'])\n",
    "    Oscar = URIRef(MO['oscar_'+cat.replace(\" \", \"\").lower()+'_'+ str(num2words(row['ceremony'], to='ordinal'))])\n",
    "    \n",
    "    # check if there already is at least a triple about this oscar\n",
    "    if not (Oscar, None, None) in g:    \n",
    "        # check if the oscar is already in the graph\n",
    "        g.add((Oscar, RDF.type, MO.Oscar))\n",
    "        g.add((Oscar, MO['category'], Literal(row['category'].lower(), datatype=XSD.string)))\n",
    "        g.add((Oscar, MO['year'], Literal(row['year_ceremony'], datatype=XSD.gYear)))\n",
    "    \n",
    "    # check if there is a name matching the people, meaning that the oscar can be associated to a person\n",
    "    if (people[\"name\"] == row[\"name\"]).any() == True :\n",
    "        #there is a person with this name\n",
    "        # Create the node about the person\n",
    "        # note that we do not add this resource to the database (created before)\n",
    "        Person = URIRef(MO[people[people[\"name\"]==row[\"name\"]].index[0]])\n",
    "        if row['winner']:\n",
    "            g.add((Person, MO['winner'], Oscar))\n",
    "        else:\n",
    "            g.add((Person, MO['nominated'], Oscar))\n",
    "    \n",
    "    # an oscar for a person is also to be considered an oscar for the movie\n",
    "    # check if the movie is in our DB\n",
    "    if (movies[\"original_title\"] == row[\"film\"]).any():\n",
    "        # there is a movie with this title\n",
    "        Movie = URIRef(MO[movies[movies[\"original_title\"]==row[\"film\"]].index[0]])\n",
    "        if row['winner']:\n",
    "            g.add((Movie, MO['winner'], Oscar))\n",
    "        else:\n",
    "            g.add((Movie, MO['nominated'], Oscar))\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"mo\", MO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: user 2.88 s, sys: 60.9 ms, total: 2.94 s\n",
      "Wall time: 4.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'oscars.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f425395ffb6f3e0d5e7129e84b03af183902aa6dc13056c35a8ecfb032782f4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
